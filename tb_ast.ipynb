{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c8d73b",
   "metadata": {},
   "source": [
    "### Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "524f2a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from models import ASTModel\n",
    "import dataloader\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from traintest import train, validate\n",
    "\n",
    "sys.path.append('./src') \n",
    "os.environ['TORCH_HOME'] = '../pretrained_models'  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02700603",
   "metadata": {},
   "source": [
    "### Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9ed9f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "AST 5-FOLD CV DATA PREPARATION SUMMARY\n",
      "==================================================\n",
      "\n",
      "[ FOLD 1 ]\n",
      "  TRAIN SET (Patients: 12 ‡∏Ñ‡∏ô) -> IDs: 001, 002, 003, 005, 006, 007, 008, 009, 011, 012, 013, 016\n",
      "      Samples: PTB (Class 1) = 150 | Non-PTB (Class 0) = 234\n",
      "  EVAL SET  (Patients: 3 ‡∏Ñ‡∏ô) -> IDs: 004, 014, 015\n",
      "      Samples: PTB (Class 1) =  37 | Non-PTB (Class 0) =  91\n",
      "\n",
      "[ FOLD 2 ]\n",
      "  TRAIN SET (Patients: 12 ‡∏Ñ‡∏ô) -> IDs: 001, 002, 003, 004, 006, 007, 008, 009, 011, 014, 015, 016\n",
      "      Samples: PTB (Class 1) = 167 | Non-PTB (Class 0) = 253\n",
      "  EVAL SET  (Patients: 3 ‡∏Ñ‡∏ô) -> IDs: 005, 012, 013\n",
      "      Samples: PTB (Class 1) =  20 | Non-PTB (Class 0) =  72\n",
      "\n",
      "[ FOLD 3 ]\n",
      "  TRAIN SET (Patients: 12 ‡∏Ñ‡∏ô) -> IDs: 001, 002, 003, 004, 005, 008, 009, 012, 013, 014, 015, 016\n",
      "      Samples: PTB (Class 1) = 134 | Non-PTB (Class 0) = 314\n",
      "  EVAL SET  (Patients: 3 ‡∏Ñ‡∏ô) -> IDs: 006, 007, 011\n",
      "      Samples: PTB (Class 1) =  53 | Non-PTB (Class 0) =  11\n",
      "\n",
      "[ FOLD 4 ]\n",
      "  TRAIN SET (Patients: 12 ‡∏Ñ‡∏ô) -> IDs: 001, 002, 004, 005, 006, 007, 009, 011, 012, 013, 014, 015\n",
      "      Samples: PTB (Class 1) = 114 | Non-PTB (Class 0) = 323\n",
      "  EVAL SET  (Patients: 3 ‡∏Ñ‡∏ô) -> IDs: 003, 008, 016\n",
      "      Samples: PTB (Class 1) =  73 | Non-PTB (Class 0) =   2\n",
      "\n",
      "[ FOLD 5 ]\n",
      "  TRAIN SET (Patients: 12 ‡∏Ñ‡∏ô) -> IDs: 003, 004, 005, 006, 007, 008, 011, 012, 013, 014, 015, 016\n",
      "      Samples: PTB (Class 1) = 183 | Non-PTB (Class 0) = 176\n",
      "  EVAL SET  (Patients: 3 ‡∏Ñ‡∏ô) -> IDs: 001, 002, 009\n",
      "      Samples: PTB (Class 1) =   4 | Non-PTB (Class 0) = 149\n"
     ]
    }
   ],
   "source": [
    "def prepare_ast_5fold_patient_split(root_path, k_folds=5):\n",
    "    # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏£‡∏´‡∏±‡∏™‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢ (Patient ID: 00x)\n",
    "    patient_groups = {\n",
    "        \"Cough_PTB\": defaultdict(list),\n",
    "        \"Cough_Non-PTB\": defaultdict(list)\n",
    "    }\n",
    "    class_map = {\"Cough_PTB\": \"1\", \"Cough_Non-PTB\": \"0\"}\n",
    "\n",
    "    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°\n",
    "    for folder_name, label_idx in class_map.items():\n",
    "        folder_path = os.path.join(root_path, folder_name)\n",
    "        if not os.path.exists(folder_path): continue\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                patient_id = file.split('_')[0]\n",
    "                full_path = os.path.abspath(os.path.join(folder_path, file))\n",
    "                patient_groups[folder_name][patient_id].append(full_path)\n",
    "\n",
    "    # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "    all_patients = set()\n",
    "    for folder_name in patient_groups:\n",
    "        all_patients.update(patient_groups[folder_name].keys())\n",
    "    all_patients = list(all_patients)\n",
    "    \n",
    "    # ‡∏•‡πá‡∏≠‡∏Å Seed ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡πà‡∏°‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\n",
    "    random.seed(42)\n",
    "    random.shuffle(all_patients)\n",
    "\n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô 5 ‡∏Å‡∏•‡∏∏‡πà‡∏° (Folds)\n",
    "    fold_size = len(all_patients) // k_folds\n",
    "    folds = []\n",
    "    for i in range(k_folds):\n",
    "        start_idx = i * fold_size\n",
    "        # ‡πÉ‡∏´‡πâ fold ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏£‡∏±‡∏ö‡πÄ‡∏®‡∏©‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÑ‡∏õ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏•‡∏á‡∏ï‡∏±‡∏ß)\n",
    "        end_idx = (i + 1) * fold_size if i < k_folds - 1 else len(all_patients)\n",
    "        folds.append(all_patients[start_idx:end_idx])\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    print(\"AST 5-FOLD CV DATA PREPARATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå JSON ‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏ö‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Fold\n",
    "    for fold_idx, eval_ids in enumerate(folds, 1):\n",
    "        # ‡∏Å‡∏•‡∏∏‡πà‡∏° Eval ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô ‡∏™‡πà‡∏ß‡∏ô Train ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "        train_ids = [pid for pid in all_patients if pid not in eval_ids]\n",
    "        \n",
    "        train_list, eval_list = [], []\n",
    "        stats = {\n",
    "            \"train\": {\"ptb\": 0, \"non_ptb\": 0},\n",
    "            \"eval\": {\"ptb\": 0, \"non_ptb\": 0}\n",
    "        }\n",
    "\n",
    "        for folder_name, groups in patient_groups.items():\n",
    "            for p_id, paths in groups.items():\n",
    "                for path in paths:\n",
    "                    item = {\"wav\": path, \"labels\": class_map[folder_name]}\n",
    "                    if p_id in eval_ids:\n",
    "                        eval_list.append(item)\n",
    "                        if class_map[folder_name] == \"1\": stats[\"eval\"][\"ptb\"] += 1\n",
    "                        else: stats[\"eval\"][\"non_ptb\"] += 1\n",
    "                    else:\n",
    "                        train_list.append(item)\n",
    "                        if class_map[folder_name] == \"1\": stats[\"train\"][\"ptb\"] += 1\n",
    "                        else: stats[\"train\"][\"non_ptb\"] += 1\n",
    "\n",
    "        # 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Fold\n",
    "        with open(f'train_data_fold_{fold_idx}.json', 'w') as f:\n",
    "            json.dump({\"data\": train_list}, f, indent=4)\n",
    "        with open(f'eval_data_fold_{fold_idx}.json', 'w') as f:\n",
    "            json.dump({\"data\": eval_list}, f, indent=4)\n",
    "\n",
    "        # 4. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡∏≠‡∏á Fold ‡∏ô‡∏±‡πâ‡∏ô‡πÜ\n",
    "        print(f\"\\n[ FOLD {fold_idx} ]\")\n",
    "        print(f\"  TRAIN SET (Patients: {len(train_ids)} ‡∏Ñ‡∏ô) -> IDs: {', '.join(sorted(train_ids))}\")\n",
    "        print(f\"      Samples: PTB (Class 1) = {stats['train']['ptb']:3d} | Non-PTB (Class 0) = {stats['train']['non_ptb']:3d}\")\n",
    "        print(f\"  EVAL SET  (Patients: {len(eval_ids)} ‡∏Ñ‡∏ô) -> IDs: {', '.join(sorted(eval_ids))}\")\n",
    "        print(f\"      Samples: PTB (Class 1) = {stats['eval']['ptb']:3d} | Non-PTB (Class 0) = {stats['eval']['non_ptb']:3d}\")\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "prepare_ast_5fold_patient_split(\"./Data\", k_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a9416eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üöÄ STARTING FOLD 1/5\n",
      "========================================\n",
      "---------------the train dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process audioset\n",
      "use dataset mean -3.383 and std 5.116 to normalize the input.\n",
      "number of classes is 2\n",
      "---------------the evaluation dataloader---------------\n",
      "now using following mask: 0 freq, 0 time\n",
      "now using mix-up with rate 0.000000\n",
      "now process audioset\n",
      "use dataset mean -3.383 and std 5.116 to normalize the input.\n",
      "number of classes is 2\n",
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=108\n",
      "running on cpu\n",
      "Total parameter number is : 86.880 million\n",
      "Total trainable parameter number is : 86.880 million\n",
      "now training with audioset, main metrics: acc, loss function: CrossEntropyLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x000001E284ECB820>\n",
      "The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epochs\n",
      "current #steps=0, #epochs=1\n",
      "start training...\n",
      "---------------\n",
      "2026-02-19 23:56:32.877380\n",
      "current #epochs=1, #steps=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\AST-With-TB-Classify\\venvast\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:116: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm-up learning rate is 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 55\u001b[0m\n\u001b[0;32m     47\u001b[0m args \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mNamespace(\n\u001b[0;32m     48\u001b[0m     exp_dir\u001b[38;5;241m=\u001b[39mexp_dir, dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudioset\u001b[39m\u001b[38;5;124m'\u001b[39m, n_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, \n\u001b[0;32m     49\u001b[0m     n_print_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, save_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCE\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     50\u001b[0m     lrscheduler_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, lrscheduler_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, lrscheduler_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \n\u001b[0;32m     51\u001b[0m     warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, wa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, wa_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, wa_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[0;32m     52\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 5. ‡πÄ‡∏£‡∏¥‡πà‡∏° Train\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mast_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# 6. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (Validate) ‡∏î‡πâ‡∏ß‡∏¢ Best Model ‡∏Ç‡∏≠‡∏á Fold ‡∏ô‡∏µ‡πâ\u001b[39;00m\n\u001b[0;32m     58\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mexp_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/models/best_audio_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mz:\\AST-With-TB-Classify\\./src\\traintest.py:140\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(audio_model, train_loader, test_loader, args)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# optimization if amp is not used\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# optimiztion if amp is used\u001b[39;00m\n\u001b[0;32m    139\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 140\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    142\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mz:\\AST-With-TB-Classify\\venvast\\lib\\site-packages\\torch\\tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    238\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    239\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    244\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mz:\\AST-With-TB-Classify\\venvast\\lib\\site-packages\\torch\\autograd\\__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 145\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Fold\n",
    "fold_results = {\"acc\": [], \"auc\": []}\n",
    "\n",
    "# ‡∏ß‡∏ô‡∏•‡∏π‡∏õ 5 Folds (1 ‡∏ñ‡∏∂‡∏á 5)\n",
    "for fold in range(1, 6):\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"üöÄ STARTING FOLD {fold}/5\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    # 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ü‡∏•‡πå JSON ‡∏Ç‡∏≠‡∏á Fold ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "    train_json = f'train_data_fold_{fold}.json'\n",
    "    eval_json = f'eval_data_fold_{fold}.json'\n",
    "    \n",
    "    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö Checkpoint ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Fold ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡∏ö‡∏Å‡∏±‡∏ô\n",
    "    exp_dir = f'./exp/tb_ast_p_fold_{fold}'\n",
    "    os.makedirs(f'{exp_dir}/models', exist_ok=True)\n",
    "\n",
    "    # 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Data Config (‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)\n",
    "    train_audio_conf = {'num_mel_bins': 128, 'target_length': 100, 'freqm': 0, 'timem': 0, 'mixup': 0.0, 'dataset': 'audioset', 'mode': 'train', 'mean': -3.3831, 'std': 5.1156, 'noise': False, 'skip_norm': False}\n",
    "    eval_audio_conf = {'num_mel_bins': 128, 'target_length': 100, 'freqm': 0, 'timem': 0, 'mixup': 0.0, 'dataset': 'audioset', 'mode': 'evaluation', 'mean': -3.3831, 'std': 5.1156, 'noise': False, 'skip_norm': False}\n",
    "    \n",
    "    BATCH_SIZE = 8\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader ‡∏Ç‡∏≠‡∏á Fold ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataloader.AudiosetDataset(train_json, label_csv='class_labels_indices.csv', audio_conf=train_audio_conf),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True\n",
    "    )\n",
    "    eval_loader = torch.utils.data.DataLoader(\n",
    "        dataloader.AudiosetDataset(eval_json, label_csv='class_labels_indices.csv', audio_conf=eval_audio_conf),\n",
    "        batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=0, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á AST-P Model ‡πÉ‡∏´‡∏°‡πà (‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å Fold ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏î‡∏¥‡∏°)\n",
    "    ast_model = ASTModel(\n",
    "        label_dim=2, \n",
    "        fstride=10, \n",
    "        tstride=10, \n",
    "        input_fdim=128, \n",
    "        input_tdim=100, \n",
    "        imagenet_pretrain=True, \n",
    "        audioset_pretrain=True,  # ‡πÉ‡∏ä‡πâ AudioSet Pretrained (AST-P)\n",
    "        model_size='base384'     # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AST-P\n",
    "    )\n",
    "\n",
    "    # 4. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Training Arguments\n",
    "    args = argparse.Namespace(\n",
    "        exp_dir=exp_dir, dataset='audioset', n_class=2, lr=1e-5, n_epochs=30, batch_size=BATCH_SIZE, \n",
    "        n_print_steps=10, save_model=True, loss='CE', metrics='acc', \n",
    "        lrscheduler_start=10, lrscheduler_step=5, lrscheduler_decay=0.5, \n",
    "        warmup=True, wa=True, wa_start=1, wa_end=30\n",
    "    )\n",
    "\n",
    "    # 5. ‡πÄ‡∏£‡∏¥‡πà‡∏° Train\n",
    "    train(ast_model, train_loader, eval_loader, args)\n",
    "\n",
    "    # 6. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (Validate) ‡∏î‡πâ‡∏ß‡∏¢ Best Model ‡∏Ç‡∏≠‡∏á Fold ‡∏ô‡∏µ‡πâ\n",
    "    best_model_path = f'{args.exp_dir}/models/best_audio_model.pth'\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "    best_model = ASTModel(label_dim=2, fstride=10, tstride=10, input_fdim=128, input_tdim=100, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=False)\n",
    "    best_model = torch.nn.DataParallel(best_model)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    \n",
    "    stats, eval_loss = validate(best_model, eval_loader, args, epoch='best')\n",
    "    acc = stats[0]['acc']\n",
    "    auc = stats[0]['auc']\n",
    "    \n",
    "    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÑ‡∏ß‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≠‡∏ô‡∏à‡∏ö\n",
    "    fold_results[\"acc\"].append(acc)\n",
    "    fold_results[\"auc\"].append(auc)\n",
    "\n",
    "    print(f\"\\n[ RESULT FOLD {fold} ] Accuracy: {acc:.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "# 7. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏£‡∏ß‡∏°‡πÅ‡∏ö‡∏ö Standard 5-Cross Validation\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(\"üèÜ FINAL 5-FOLD CV RESULTS\")\n",
    "print(f\"{'='*40}\")\n",
    "print(f\"Averaged Accuracy : {np.mean(fold_results['acc']):.4f} ¬± {np.std(fold_results['acc']):.4f}\")\n",
    "print(f\"Averaged AUC      : {np.mean(fold_results['auc']):.4f} ¬± {np.std(fold_results['auc']):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
