{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "# เพิ่ม path ของ folder 'src' เพื่อให้ import ไฟล์ของ AST ได้\n",
    "sys.path.append('./src') \n",
    "os.environ['TORCH_HOME'] = '../pretrained_models'  \n",
    "\n",
    "from models import ASTModel\n",
    "import dataloader\n",
    "\n",
    "# ตรวจสอบ Device (ถ้ามี GPU ก็ใช้ GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ast_patient_split_clean(root_path, train_ratio=0.8):\n",
    "    # 1. จัดกลุ่มไฟล์ตามรหัสผู้ป่วย (Patient ID: 00x)\n",
    "    patient_groups = {\n",
    "        \"Cough_PTB\": defaultdict(list),\n",
    "        \"Cough_Non-PTB\": defaultdict(list)\n",
    "    }\n",
    "    \n",
    "    class_map = {\"Cough_PTB\": \"1\", \"Cough_Non-PTB\": \"0\"}\n",
    "\n",
    "    for folder_name, label_idx in class_map.items():\n",
    "        folder_path = os.path.join(root_path, folder_name)\n",
    "        if not os.path.exists(folder_path): continue\n",
    "            \n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                # ดึง Patient ID (00x) จากส่วนหน้าสุดของชื่อไฟล์\n",
    "                patient_id = file.split('_')[0] \n",
    "                full_path = os.path.abspath(os.path.join(folder_path, file))\n",
    "                patient_groups[folder_name][patient_id].append(full_path)\n",
    "\n",
    "    train_list, eval_list = [], []\n",
    "    stats = {\n",
    "        \"train\": {\"patients\": [], \"ptb_samples\": 0, \"non_ptb_samples\": 0},\n",
    "        \"eval\": {\"patients\": [], \"ptb_samples\": 0, \"non_ptb_samples\": 0}\n",
    "    }\n",
    "\n",
    "    # 2. แบ่งข้อมูลรายกลุ่มผู้ป่วย (Patient Level) แยกตามคลาส\n",
    "    for folder_name, groups in patient_groups.items():\n",
    "        patient_ids = list(groups.keys())\n",
    "        random.seed(42) # ล็อก Seed เพื่อให้ผลลัพธ์คงที่\n",
    "        random.shuffle(patient_ids)\n",
    "        \n",
    "        split_idx = int(len(patient_ids) * train_ratio)\n",
    "        train_ids = patient_ids[:split_idx]\n",
    "        eval_ids = patient_ids[split_idx:]\n",
    "\n",
    "        # กลุ่ม Train\n",
    "        for p_id in train_ids:\n",
    "            stats[\"train\"][\"patients\"].append(p_id) # เก็บเฉพาะรหัสผู้ป่วย\n",
    "            for path in groups[p_id]:\n",
    "                train_list.append({\"wav\": path, \"labels\": class_map[folder_name]})\n",
    "                if folder_name == \"Cough_PTB\": stats[\"train\"][\"ptb_samples\"] += 1\n",
    "                else: stats[\"train\"][\"non_ptb_samples\"] += 1\n",
    "        \n",
    "        # กลุ่ม Eval\n",
    "        for p_id in eval_ids:\n",
    "            stats[\"eval\"][\"patients\"].append(p_id) # เก็บเฉพาะรหัสผู้ป่วย\n",
    "            for path in groups[p_id]:\n",
    "                eval_list.append({\"wav\": path, \"labels\": class_map[folder_name]})\n",
    "                if folder_name == \"Cough_PTB\": stats[\"eval\"][\"ptb_samples\"] += 1\n",
    "                else: stats[\"eval\"][\"non_ptb_samples\"] += 1\n",
    "\n",
    "    # 3. บันทึกไฟล์ JSON\n",
    "    with open('train_data.json', 'w') as f:\n",
    "        json.dump({\"data\": train_list}, f, indent=4)\n",
    "    with open('eval_data.json', 'w') as f:\n",
    "        json.dump({\"data\": eval_list}, f, indent=4)\n",
    "\n",
    "    # 4. แสดงผลสรุปที่สะอาดขึ้น\n",
    "    print(\"=\"*50)\n",
    "    print(\"AST DATA PREPARATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\n[TRAIN SET]\")\n",
    "    print(f\"Total Unique Patients: {len(stats['train']['patients'])} คน\")\n",
    "    print(f\"Patient IDs: {', '.join(sorted(stats['train']['patients']))}\")\n",
    "    print(f\"Samples: PTB (Class 1) = {stats['train']['ptb_samples']} | Non-PTB (Class 0) = {stats['train']['non_ptb_samples']}\")\n",
    "    \n",
    "    print(f\"\\n[EVAL SET]\")\n",
    "    print(f\"Total Unique Patients: {len(stats['eval']['patients'])} คน\")\n",
    "    print(f\"Patient IDs: {', '.join(sorted(stats['eval']['patients']))}\")\n",
    "    print(f\"Samples: PTB (Class 1) = {stats['eval']['ptb_samples']} | Non-PTB (Class 0) = {stats['eval']['non_ptb_samples']}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# เรียกใช้งาน\n",
    "prepare_ast_patient_split_clean(\"./Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9416eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ค่า Config สำหรับเสียงไอ 1 วินาทีของคุณ\n",
    "audio_conf = {\n",
    "    'num_mel_bins': 128, \n",
    "    'target_length': 100,   # 1 วินาที\n",
    "    'freqm': 0,            # Frequency Masking (ปิดแถบความถี่เพื่อ Augment)\n",
    "    'timem': 0,            # Time Masking (ลดลงจาก 192 เพราะเสียงเราสั้น)\n",
    "    'mixup': 0,           # Mixup augmentation\n",
    "    'dataset': 'audioset',\n",
    "    'mode': 'train',\n",
    "    'mean': -3.3831,        # ค่าที่คุณคำนวณได้\n",
    "    'std': 5.1156,          # ค่าที่คุณคำนวณได้\n",
    "    'noise': False,\n",
    "    'skip_norm': False      # ต้องเป็น False เพื่อให้มัน Normalize ข้อมูลให้เรา\n",
    "}\n",
    "\n",
    "# สร้าง Dataset\n",
    "train_dataset = dataloader.AudiosetDataset(\n",
    "    'train_data.json', \n",
    "    label_csv='class_labels_indices.csv', \n",
    "    audio_conf=audio_conf\n",
    ")\n",
    "\n",
    "# สร้าง DataLoader (ดึงทีละ 4 ไฟล์พอ เพื่อดูตัวอย่าง)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=4, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"Dataset Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ดึงข้อมูลมา 1 Batch\n",
    "# for i, (audio_input, labels) in enumerate(train_loader):\n",
    "#     # audio_input shape: [batch_size, time_frame, freq_bins]\n",
    "#     print(f\"Input Shape: {audio_input.shape}\") \n",
    "#     print(f\"Labels: {labels}\") # จะเห็นเป็น One-hot encoding หรือ Index\n",
    "\n",
    "#     # ลองวาด Spectrogram ของรูปแรกใน Batch\n",
    "#     spec = audio_input[0].detach().cpu().numpy()\n",
    "    \n",
    "#     # พล็อต Spectrogram\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "#     # ต้อง Transpose (.T) เพื่อให้แกน X เป็นเวลา แกน Y เป็นความถี่ (เหมือนรูปทั่วไป)\n",
    "#     plt.imshow(spec.T, origin='lower', aspect='auto', cmap='inferno')\n",
    "#     plt.title(f\"Spectrogram Input (Normalized & Masked)\\nLabel: {labels[0]}\")\n",
    "#     plt.xlabel(\"Time Frames (Total 100)\")\n",
    "#     plt.ylabel(\"Mel Frequency Bins (128)\")\n",
    "#     plt.colorbar(format='%+2.0f dB')\n",
    "#     plt.show()\n",
    "    \n",
    "#     break # ดูแค่ Batch เดียวพอ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ced9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Label → ชื่อ Folder ---\n",
    "LABEL_TO_FOLDER = {\n",
    "    \"1\": \"PTB\",\n",
    "    \"0\": \"Non-TB\"\n",
    "}\n",
    "\n",
    "# --- สร้าง Directory Structure ---\n",
    "ROOT_DIR = './spectrogram'\n",
    "for sub in ['ptFile', 'img']:\n",
    "    for cls in ['PTB', 'Non-TB']:\n",
    "        os.makedirs(os.path.join(ROOT_DIR, sub, cls), exist_ok=True)\n",
    "\n",
    "print(\"Folder structure created:\")\n",
    "print(\"  spectrogram/ptFile/PTB  ← normalized Kaldi fbank (.pt) สำหรับ model\")\n",
    "print(\"  spectrogram/ptFile/Non-TB\")\n",
    "print(\"  spectrogram/img/PTB     ← de-normalized fbank visualized (.png) สำหรับดูรูป\")\n",
    "print(\"  spectrogram/img/Non-TB\\n\")\n",
    "\n",
    "# --- รวมข้อมูลจากทั้ง train และ eval JSON ---\n",
    "all_audio_list = []\n",
    "for json_file in ['train_data.json', 'eval_data.json']:\n",
    "    with open(json_file, 'r') as f:\n",
    "        data_json = json.load(f)\n",
    "    all_audio_list.extend(data_json['data'])\n",
    "\n",
    "print(f\"Total files to process: {len(all_audio_list)}\")\n",
    "\n",
    "# --- สร้าง Dataset รวมจากข้อมูลทั้งหมด ---\n",
    "import tempfile\n",
    "combined_json_path = os.path.join(tempfile.gettempdir(), 'combined_data.json')\n",
    "with open(combined_json_path, 'w') as f:\n",
    "    json.dump({\"data\": all_audio_list}, f)\n",
    "\n",
    "combined_dataset = dataloader.AudiosetDataset(\n",
    "    combined_json_path,\n",
    "    label_csv='class_labels_indices.csv',\n",
    "    audio_conf=audio_conf\n",
    ")\n",
    "\n",
    "# Dataset mean/std ที่ใช้ normalize (จาก audio_conf)\n",
    "NORM_MEAN = audio_conf['mean']   # -3.3831\n",
    "NORM_STD  = audio_conf['std']    # 5.1156\n",
    "\n",
    "# --- วนลูปสร้างและบันทึก Spectrogram ---\n",
    "# Spectrogram ที่ได้จาก dataloader คือ Kaldi Mel Filterbank (fbank) ตามที่ README ระบุ:\n",
    "#   - torchaudio.compliance.kaldi.fbank (htk_compat=True, hanning window)\n",
    "#   - 128 mel bins, 10ms frame shift, 16kHz\n",
    "#   - Normalize: (fbank - mean) / (std * 2)  →  ~0 mean, ~0.5 std\n",
    "print(\"Starting Spectrogram Extraction...\")\n",
    "for i in tqdm(range(len(combined_dataset))):\n",
    "    spec, label = combined_dataset[i]   # spec: normalized fbank [time=100, freq=128]\n",
    "\n",
    "    label_str = all_audio_list[i]['labels']\n",
    "    class_folder = LABEL_TO_FOLDER.get(label_str, \"Non-TB\")\n",
    "\n",
    "    original_wav_path = all_audio_list[i]['wav']\n",
    "    base_name = os.path.basename(original_wav_path).replace('.wav', '')\n",
    "\n",
    "    # 1. บันทึก .pt ← normalized fbank ตรงๆ (ค่าที่ model ต้องการตาม README)\n",
    "    pt_path = os.path.join(ROOT_DIR, 'ptFile', class_folder, base_name + '.pt')\n",
    "    torch.save(spec, pt_path)\n",
    "\n",
    "    # 2. บันทึก .png ← de-normalize กลับสู่ค่า log-mel energy จริง แล้ว visualize\n",
    "    #    de-norm: fbank_original = spec * (std * 2) + mean\n",
    "    img_path = os.path.join(ROOT_DIR, 'img', class_folder, base_name + '.png')\n",
    "    fbank_orig = spec.numpy() * (NORM_STD * 2) + NORM_MEAN   # [time, freq] in log-mel dB\n",
    "    fbank_disp = fbank_orig.T[::-1].copy()                    # [freq, time], low freq at bottom\n",
    "\n",
    "    # Normalize เพื่อ map สีเท่านั้น (min-max ของ sample นี้)\n",
    "    vmin, vmax = fbank_disp.min(), fbank_disp.max()\n",
    "    fbank_norm = (fbank_disp - vmin) / (vmax - vmin + 1e-8)\n",
    "\n",
    "    rgba = (cm.inferno(fbank_norm) * 255).astype(np.uint8)    # apply inferno colormap\n",
    "    img = Image.fromarray(rgba[:, :, :3], mode='RGB')\n",
    "    # resize 8x ให้ดูง่าย (100x128 → 800x1024 px)\n",
    "    img = img.resize((img.width * 8, img.height * 8), Image.NEAREST)\n",
    "    img.save(img_path)\n",
    "\n",
    "print(f\"\\nDone! Spectrograms saved in '{ROOT_DIR}/'\")\n",
    "print(f\"  PTB    : {len([x for x in all_audio_list if x['labels']=='1'])} files\")\n",
    "print(f\"  Non-TB : {len([x for x in all_audio_list if x['labels']=='0'])} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a494f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "achitecture = ASTModel(\n",
    "            label_dim=2,             # จำนวนคลาส (PTB, NON-PTB)\n",
    "            fstride=10,              # ต้องเป็น 10 สำหรับ AudioSet pretrain\n",
    "            tstride=10,              # ต้องเป็น 10 สำหรับ AudioSet pretrain\n",
    "            input_fdim=128,          # ค่ามาตรฐาน\n",
    "            input_tdim=100,          # ปรับตามความยาว spectrogram ของคุณ \n",
    "            imagenet_pretrain=True,  # เปิดใช้งาน\n",
    "            audioset_pretrain=True,  # เปิดใช้งาน (AST-P)\n",
    "            model_size='base384'     # ต้องเป็น base384\n",
    "        )\n",
    "ast_mdl = achitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== TB Classification Training with AST-P =====\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "from traintest import train, validate\n",
    "\n",
    "# --- 1. DataLoader สำหรับ Train และ Eval ---\n",
    "# audio_conf สำหรับ Train (เปิด SpecAugment)\n",
    "train_audio_conf = {\n",
    "    'num_mel_bins': 128,\n",
    "    'target_length': 100,\n",
    "    'freqm': 24,          # mask 24/128 frequency bins (ตาม README แนะนำ ~48 แต่ข้อมูลน้อยใช้ 24)\n",
    "    'timem': 20,          # mask 20% ของ time frames\n",
    "    'mixup': 0.0,         # ข้อมูลน้อย ปิด mixup\n",
    "    'dataset': 'audioset',\n",
    "    'mode': 'train',\n",
    "    'mean': -3.3831,\n",
    "    'std': 5.1156,\n",
    "    'noise': False,\n",
    "    'skip_norm': False\n",
    "}\n",
    "\n",
    "# audio_conf สำหรับ Eval (ปิด Augmentation ทั้งหมด)\n",
    "eval_audio_conf = {\n",
    "    'num_mel_bins': 128,\n",
    "    'target_length': 100,\n",
    "    'freqm': 0,\n",
    "    'timem': 0,\n",
    "    'mixup': 0.0,\n",
    "    'dataset': 'audioset',\n",
    "    'mode': 'evaluation',\n",
    "    'mean': -3.3831,\n",
    "    'std': 5.1156,\n",
    "    'noise': False,\n",
    "    'skip_norm': False\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 8  # ข้อมูลน้อย ใช้ batch เล็ก\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudiosetDataset('train_data.json', label_csv='class_labels_indices.csv', audio_conf=train_audio_conf),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudiosetDataset('eval_data.json', label_csv='class_labels_indices.csv', audio_conf=eval_audio_conf),\n",
    "    batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Eval  samples: {len(eval_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. สร้าง AST-P Model (AudioSet Pretrained) ---\n",
    "ast_model = ASTModel(\n",
    "    label_dim=2,              # PTB vs Non-TB\n",
    "    fstride=10,\n",
    "    tstride=10,\n",
    "    input_fdim=128,\n",
    "    input_tdim=100,\n",
    "    imagenet_pretrain=True,\n",
    "    audioset_pretrain=True,   # AST-P: ใช้ AudioSet pretrained weights\n",
    "    model_size='base384'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4065808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3. ตั้งค่า Training Arguments ---\n",
    "args = argparse.Namespace(\n",
    "    # Experiment\n",
    "    exp_dir        = './exp/tb_ast_p',\n",
    "\n",
    "    # Data\n",
    "    dataset        = 'audioset',\n",
    "\n",
    "    # Model\n",
    "    n_class        = 2,\n",
    "\n",
    "    # Training\n",
    "    lr             = 1e-5,      # AST ต้องการ lr เล็กมาก (README แนะนำ 10x เล็กกว่า CNN)\n",
    "    n_epochs       = 30,\n",
    "    batch_size     = BATCH_SIZE,\n",
    "    n_print_steps  = 10,\n",
    "    save_model     = True,\n",
    "\n",
    "    # Loss & Metrics\n",
    "    # CE + acc เหมาะกับ binary classification (2 class, single-label)\n",
    "    loss           = 'CE',\n",
    "    metrics        = 'acc',\n",
    "\n",
    "    # Learning Rate Scheduler (MultiStepLR)\n",
    "    # เริ่ม decay ที่ epoch 10, ทุก 5 epoch, decay rate 0.5\n",
    "    lrscheduler_start = 10,\n",
    "    lrscheduler_step  = 5,\n",
    "    lrscheduler_decay = 0.5,\n",
    "\n",
    "    # Warmup\n",
    "    warmup         = True,\n",
    ")\n",
    "\n",
    "os.makedirs(f'{args.exp_dir}/models', exist_ok=True)\n",
    "print(f\"Experiment will be saved to: {args.exp_dir}\")\n",
    "print(f\"Training config: lr={args.lr}, epochs={args.n_epochs}, loss={args.loss}, metrics={args.metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. รัน Training ---\n",
    "train(ast_model, train_loader, eval_loader, args)\n",
    "\n",
    "best_model_path = f'{args.exp_dir}/models/best_audio_model.pth'\n",
    "print(f\"\\nTraining complete. Best model saved to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ตรวจสอบว่าไฟล์โมเดลมีอยู่หรือไม่\n",
    "if not os.path.exists(best_model_path):\n",
    "    raise FileNotFoundError(f\"Model file not found: {best_model_path}. Ensure training is completed and the model is saved.\")\n",
    "\n",
    "# โหลด best model\n",
    "best_model = ASTModel(label_dim=2, fstride=10, tstride=10,\n",
    "                      input_fdim=128, input_tdim=100,\n",
    "                      imagenet_pretrain=False, audioset_pretrain=False,\n",
    "                      model_size='base384', verbose=False)\n",
    "best_model = torch.nn.DataParallel(best_model)\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "print(f\"Loaded best model from: {best_model_path}\")\n",
    "\n",
    "# รัน validate บน eval set\n",
    "stats, eval_loss = validate(best_model, eval_loader, args, epoch='best')\n",
    "acc  = stats[0]['acc']\n",
    "auc  = stats[0]['auc']\n",
    "print(f\"\\n===== Best Model Evaluation =====\")\n",
    "print(f\"Accuracy : {acc:.4f} ({acc*100:.2f}%)\")\n",
    "print(f\"AUC      : {auc:.4f}\")\n",
    "print(f\"Eval Loss: {eval_loss:.4f}\")\n",
    "\n",
    "# พล็อต training curve จาก result.csv\n",
    "result_path = f'{args.exp_dir}/result.csv'\n",
    "if os.path.exists(result_path):\n",
    "    cols = ['acc/mAP', 'mAUC', 'avg_precision', 'avg_recall', 'd_prime',\n",
    "            'train_loss', 'valid_loss', 'cum_acc/mAP', 'cum_mAUC', 'lr']\n",
    "    df = pd.read_csv(result_path, header=None, names=cols)\n",
    "    df = df[df['acc/mAP'] != 0]  # ตัด epoch ที่ยังไม่ได้รัน\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    axes[0].plot(df['acc/mAP'], marker='o', label='Acc')\n",
    "    axes[0].plot(df['cum_acc/mAP'], marker='s', linestyle='--', label='Cum Acc')\n",
    "    axes[0].set_title('Accuracy per Epoch')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    axes[1].plot(df['train_loss'], marker='o', label='Train Loss')\n",
    "    axes[1].plot(df['valid_loss'], marker='s', linestyle='--', label='Eval Loss')\n",
    "    axes[1].set_title('Loss per Epoch')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    axes[2].plot(df['mAUC'], marker='o', label='AUC')\n",
    "    axes[2].set_title('AUC per Epoch')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
