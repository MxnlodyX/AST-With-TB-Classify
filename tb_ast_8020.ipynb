{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a609e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\AST-With-TB-Classify\\venvast\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "z:\\AST-With-TB-Classify\\venvast\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py:118: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
      "z:\\AST-With-TB-Classify\\venvast\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('./src')\n",
    "os.environ['TORCH_HOME'] = '../pretrained_models'\n",
    "\n",
    "from models import ASTModel\n",
    "import dataloader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from traintest import train, validate\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6586c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AST DATASET PREPARATION SUMMARY (3-Way Patient-Level Split)\n",
      "======================================================================\n",
      " TRAIN SET (Total Patients: 9)\n",
      "    PTB ID: ['009', '011', '015']\n",
      "    Non-PTB ID: ['001', '002', '003', '007', '013', '014']\n",
      "    Total Audio Files: 294 (PTB: 42 files | Non-PTB: 252 files)\n",
      " VALIDATION SET (Total Patients: 3)\n",
      "    PTB ID: ['008']\n",
      "    Non-PTB ID: ['004', '005']\n",
      "    Total Audio Files: 115 (PTB: 42 files | Non-PTB: 73 files)\n",
      " TEST SET (Total Patients: 3)\n",
      "    PTB ID: ['006', '012', '016']\n",
      "    Non-PTB ID: []\n",
      "    Total Audio Files: 103 (PTB: 103 files | Non-PTB: 0 files)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ STARTING AST-P SINGLE RUN (80/20 SPLIT) WITH VISUALIZATION\")\n",
    "# 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "exp_dir = './exp/tb_ast_p_single_run'\n",
    "os.makedirs(f'{exp_dir}/models', exist_ok=True)\n",
    "\n",
    "MEAN_NORM = -4.27\n",
    "STD_NORM = 4.57\n",
    "\n",
    "# 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Data Config ‡∏ï‡∏≤‡∏° Speechcommands V2 Recipe\n",
    "# target_length=128, freqm=48, timem=48, mixup=0.6, noise=True\n",
    "train_audio_conf = {'num_mel_bins': 128, 'target_length': 100, 'freqm': 0, 'timem': 0, 'mixup': 0.0, 'dataset': 'audioset', 'mode': 'train', 'mean': MEAN_NORM, 'std': STD_NORM, 'noise': True, 'skip_norm': False}\n",
    "eval_audio_conf  = {'num_mel_bins': 128, 'target_length': 100, 'freqm': 0,  'timem': 0,  'mixup': 0.0, 'dataset': 'audioset', 'mode': 'evaluation', 'mean': MEAN_NORM, 'std': STD_NORM, 'noise': False, 'skip_norm': False}\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader\n",
    "# ‡πÉ‡∏ä‡πâ val_data.json ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö validation ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á training (‡∏ï‡∏≤‡∏° recipe ‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å val ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å test)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudiosetDataset('train_data.json', label_csv='class_labels_indices.csv', audio_conf=train_audio_conf),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudiosetDataset('val_data.json', label_csv='class_labels_indices.csv', audio_conf=eval_audio_conf),\n",
    "    batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Spectrogram\n",
    "# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤ 1 Batch ‡∏à‡∏≤‡∏Å train_loader ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏†‡∏≤‡∏û\n",
    "sample_inputs, sample_labels = next(iter(train_loader))\n",
    "# sample_inputs ‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î [batch_size, temporal_frame_num, frequency_bin_num]\n",
    "# ‡πÄ‡∏£‡∏≤‡∏î‡∏∂‡∏á index 0 ‡∏Ç‡∏≠‡∏á Batch ‡∏°‡∏≤‡∏û‡∏•‡πá‡∏≠‡∏ï\n",
    "spec_data = sample_inputs[0].numpy()  \n",
    "label_data = torch.argmax(sample_labels[0]).item()\n",
    "class_name = \"PTB\" if label_data == 1 else \"Non-PTB\"\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "# ‡∏û‡∏•‡πá‡∏≠‡∏ï‡πÇ‡∏î‡∏¢‡∏™‡∏•‡∏±‡∏ö‡πÅ‡∏Å‡∏ô (Transpose) ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà (128) ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏Å‡∏ô Y ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ (128) ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏Å‡∏ô X\n",
    "plt.imshow(spec_data.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.title(f\"Example Log Mel Filterbank Spectrogram (Class: {class_name})\")\n",
    "plt.ylabel(\"Frequency Bins (128)\")\n",
    "plt.xlabel(\"Time Frames (128)\")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚òùÔ∏è ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå Spectrogram 128 ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Normalization ‡πÅ‡∏•‡πâ‡∏ß ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ AST Model\")\n",
    "# ==========================================\n",
    "\n",
    "# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á AST-P Model ‡∏ï‡∏≤‡∏° Speechcommands V2 Recipe\n",
    "# audioset_pretrain=False (Speechcommands ‡πÉ‡∏ä‡πâ ImageNet pretrain ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)\n",
    "# input_tdim=128 ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö target_length ‡πÉ‡∏ô audio_conf\n",
    "ast_model = ASTModel(\n",
    "    label_dim=2, \n",
    "    fstride=10, \n",
    "    tstride=10, \n",
    "    input_fdim=128, \n",
    "    input_tdim=128, \n",
    "    imagenet_pretrain=True, \n",
    "    audioset_pretrain=False,   # Speechcommands V2: audioset_pretrain=False\n",
    "    model_size='base384'\n",
    ")\n",
    "\n",
    "# 5. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Training Arguments ‡∏ï‡∏≤‡∏° Speechcommands V2 Recipe\n",
    "args = argparse.Namespace(\n",
    "    exp_dir=exp_dir,\n",
    "    dataset='speechcommands',\n",
    "    n_class=2,\n",
    "    lr=2.5e-4,            # Speechcommands V2: lr=2.5e-4\n",
    "    n_epochs=30,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_print_steps=10,\n",
    "    save_model=True,\n",
    "    loss='BCE',           # Speechcommands V2: loss=BCE\n",
    "    metrics='acc',        # Speechcommands V2: metrics=acc\n",
    "    lrscheduler_start=5,  # Speechcommands V2: lrscheduler_start=5\n",
    "    lrscheduler_step=1,   # Speechcommands V2: lrscheduler_step=1\n",
    "    lrscheduler_decay=0.85,  # Speechcommands V2: lrscheduler_decay=0.85\n",
    "    warmup=False,         # Speechcommands V2: warmup=False\n",
    "    wa=False,             # Speechcommands V2 ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Weighted Averaging\n",
    "    wa_start=1,\n",
    "    wa_end=30\n",
    ")\n",
    "\n",
    "# 6. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ Train\n",
    "print(\"\\nStarting Model Training...\")\n",
    "train(ast_model, train_loader, eval_loader, args)\n",
    "\n",
    "# 7. ‡πÇ‡∏´‡∏•‡∏î Best Model ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "best_model_path = f'{args.exp_dir}/models/best_audio_model.pth'\n",
    "best_model = ASTModel(label_dim=2, fstride=10, tstride=10, input_fdim=128, input_tdim=128, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=False)\n",
    "best_model = torch.nn.DataParallel(best_model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "stats, eval_loss = validate(best_model, eval_loader, args, epoch='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üìä [NEW] ‡∏ß‡∏≤‡∏î Confusion Matrix ‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î Eval\n",
    "# ==========================================\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(\"\\nüìà Generating Confusion Matrix...\")\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "best_model.eval() # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "with torch.no_grad():\n",
    "    for audio, labels in eval_loader:\n",
    "        audio = audio.to(device)\n",
    "        # AST Output ‡πÄ‡∏õ‡πá‡∏ô Raw Logits (‡πÑ‡∏°‡πà‡∏°‡∏µ Sigmoid/Softmax)\n",
    "        logits = best_model(audio) \n",
    "        # ‡πÉ‡∏ä‡πâ Argmax ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ Logit ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_preds.extend(preds)\n",
    "        \n",
    "        # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á labels ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (0 ‡∏´‡∏£‡∏∑‡∏≠ 1) ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå\n",
    "        all_targets.extend(torch.argmax(labels, dim=1).numpy())\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü Confusion Matrix\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-PTB (0)', 'PTB (1)'], \n",
    "            yticklabels=['Non-PTB (0)', 'PTB (1)'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('AST-P Confusion Matrix (Val Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e68244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, average_precision_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 1. ‡∏´‡∏≤ Best Epoch ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå result.csv ‡∏Ç‡∏≠‡∏á AST\n",
    "# ==========================================\n",
    "# ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á AST: [mAP, mAUC, precision, recall, d_prime, train_loss, valid_loss, cum_mAP, cum_mAUC, lr]\n",
    "csv_path = './exp/tb_ast_p_single_run/result.csv'\n",
    "df_results = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "# ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå index 1 ‡∏Ñ‡∏∑‡∏≠ mAUC ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Epoch\n",
    "best_epoch = df_results[1].idxmax() + 1\n",
    "best_mauc = df_results[1].max()\n",
    "print(f\"üåü Best Epoch: {best_epoch} (Validation AUC from log: {best_mauc:.4f})\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Probabilities) ‡∏à‡∏≤‡∏Å Best Model\n",
    "# ==========================================\n",
    "print(\" Evaluating Best Model on Evaluation Set...\")\n",
    "all_probs = []\n",
    "all_targets = []\n",
    "\n",
    "best_model.eval() # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "with torch.no_grad():\n",
    "    for audio, labels in eval_loader:\n",
    "        audio = audio.to(device)\n",
    "        logits = best_model(audio) \n",
    "        \n",
    "        # AST Output ‡πÄ‡∏õ‡πá‡∏ô Raw Logits (‡∏°‡∏µ 2 ‡∏Ñ‡πà‡∏≤ ‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô n_class=2)\n",
    "        # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ Softmax ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (0-1) ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™ 1 (PTB)\n",
    "        probs = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "        \n",
    "        # ‡∏î‡∏∂‡∏á Label ‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏£‡∏¥‡∏á\n",
    "        targets = torch.argmax(labels, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_probs.extend(probs)\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "all_probs = np.array(all_probs)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# ==========================================\n",
    "# 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ AUROC, AUPRC ‡πÅ‡∏•‡∏∞‡∏´‡∏≤ Best Threshold\n",
    "# ==========================================\n",
    "fpr, tpr, roc_thresholds = roc_curve(all_targets, all_probs)\n",
    "auroc_val = auc(fpr, tpr)\n",
    "auprc_val = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Sensitivity ‡πÅ‡∏•‡∏∞ Specificity ‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î Best Threshold\n",
    "# ==========================================\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î Threshold ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 0.5\n",
    "optimal_preds = (all_probs >= 0.5).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(all_targets, optimal_preds).ravel()\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\" Performance Metrics:\")\n",
    "print(f\" - AUROC:             {auroc_val:.4f}\")\n",
    "print(f\" - AUPRC:             {auprc_val:.4f}\")\n",
    "print(f\" - Sensitivity (TPR): {sensitivity:.4f}  (TP:{tp}, FN:{fn})\")\n",
    "print(f\" - Specificity (TNR): {specificity:.4f}  (TN:{tn}, FP:{fp})\")\n",
    "\n",
    "# 5. ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü ROC Curve ‡πÅ‡∏•‡∏∞ Confusion Matrix ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ---- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 1: ROC Curve ----\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2.5, label=f'AUROC = {auroc_val:.4f}')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# ‡∏°‡∏≤‡∏£‡πå‡∏Ñ‡∏à‡∏∏‡∏î Threshold ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "axes[0].set_title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
    "axes[0].legend(loc=\"lower right\", fontsize=11)\n",
    "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# ---- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 2: Confusion Matrix ----\n",
    "cm_optimal = confusion_matrix(all_targets, optimal_preds)\n",
    "sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-PTB (0)', 'PTB (1)'], \n",
    "            yticklabels=['Non-PTB (0)', 'PTB (1)'],\n",
    "            annot_kws={\"size\": 14}, ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_title(f'Confusion Matrix (@ Threshold {0.5:.4f})', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
