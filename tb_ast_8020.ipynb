{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6586c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AST DATASET PREPARATION SUMMARY (3-Way Patient-Level Split)\n",
      "======================================================================\n",
      "üîπ TRAIN SET (Total Patients: 9)\n",
      "    PTB ID: ['006', '008', '012', '015']\n",
      "    Non-PTB ID: ['001', '002', '003', '013', '014']\n",
      "    Total Audio Files: 392 (PTB: 151 files | Non-PTB: 241 files)\n",
      "üî∏ VALIDATION SET (Total Patients: 3)\n",
      "    PTB ID: ['009', '011']\n",
      "    Non-PTB ID: ['005']\n",
      "    Total Audio Files: 37 (PTB: 5 files | Non-PTB: 32 files)\n",
      "üî¥ TEST SET (Total Patients: 3)\n",
      "    PTB ID: ['016']\n",
      "    Non-PTB ID: ['004', '007']\n",
      "    Total Audio Files: 83 (PTB: 31 files | Non-PTB: 52 files)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from models import ASTModel\n",
    "import dataloader\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "from traintest import train, validate\n",
    "\n",
    "sys.path.append('./src') \n",
    "os.environ['TORCH_HOME'] = '../pretrained_models'  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def prepare_ast_dataset(root_path, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ 1.0 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "    assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-5, \"Ratios must sum to 1.0\"\n",
    "\n",
    "    # 1. ‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Class Map\n",
    "    patient_groups = {\n",
    "        \"Cough_PTB\": defaultdict(list),\n",
    "        \"Cough_Non-PTB\": defaultdict(list)\n",
    "    }\n",
    "    class_map = {\"Cough_PTB\": \"1\", \"Cough_Non-PTB\": \"0\"}\n",
    "\n",
    "    # 2. ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° Patient ID\n",
    "    for folder_name, label_idx in class_map.items():\n",
    "        folder_path = os.path.join(root_path, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"‚ö†Ô∏è Warning: Folder {folder_path} not found.\")\n",
    "            continue\n",
    "            \n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".wav\"):\n",
    "                patient_id = file.split('_')[0]\n",
    "                full_path = os.path.abspath(os.path.join(folder_path, file))\n",
    "                patient_groups[folder_name][patient_id].append(full_path)\n",
    "\n",
    "    # 3. ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏ö‡πà‡∏á 3 ‡∏Å‡∏•‡∏∏‡πà‡∏°\n",
    "    all_patients = set()\n",
    "    for folder_name in patient_groups:\n",
    "        all_patients.update(patient_groups[folder_name].keys())\n",
    "    \n",
    "    all_patients = list(all_patients)\n",
    "    random.seed(42) # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î seed ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "    random.shuffle(all_patients)\n",
    "\n",
    "    total_patients = len(all_patients)\n",
    "    train_split_idx = int(total_patients * train_ratio)\n",
    "    val_split_idx = train_split_idx + int(total_patients * val_ratio)\n",
    "\n",
    "    train_ids = all_patients[:train_split_idx]\n",
    "    val_ids = all_patients[train_split_idx:val_split_idx]\n",
    "    test_ids = all_patients[val_split_idx:]\n",
    "\n",
    "    # 4. ‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á List ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö JSON ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å ID ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
    "    train_list, val_list, test_list = [], [], []\n",
    "    \n",
    "    # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö ID ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏û‡∏∑‡πà‡∏≠ Print Summary\n",
    "    summary_ids = {\n",
    "        \"train_ptb\": set(), \"train_non_ptb\": set(),\n",
    "        \"val_ptb\": set(), \"val_non_ptb\": set(),\n",
    "        \"test_ptb\": set(), \"test_non_ptb\": set()\n",
    "    }\n",
    "\n",
    "    for folder_name, groups in patient_groups.items():\n",
    "        is_ptb = (folder_name == \"Cough_PTB\")\n",
    "        \n",
    "        for p_id, paths in groups.items():\n",
    "            for path in paths:\n",
    "                item = {\"wav\": path, \"labels\": class_map[folder_name]}\n",
    "                \n",
    "                if p_id in train_ids:\n",
    "                    train_list.append(item)\n",
    "                    if is_ptb: summary_ids[\"train_ptb\"].add(p_id)\n",
    "                    else: summary_ids[\"train_non_ptb\"].add(p_id)\n",
    "                elif p_id in val_ids:\n",
    "                    val_list.append(item)\n",
    "                    if is_ptb: summary_ids[\"val_ptb\"].add(p_id)\n",
    "                    else: summary_ids[\"val_non_ptb\"].add(p_id)\n",
    "                elif p_id in test_ids:\n",
    "                    test_list.append(item)\n",
    "                    if is_ptb: summary_ids[\"test_ptb\"].add(p_id)\n",
    "                    else: summary_ids[\"test_non_ptb\"].add(p_id)\n",
    "\n",
    "    # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö dataloader.py ‡∏Ç‡∏≠‡∏á AST)\n",
    "    with open('train_data.json', 'w') as f:\n",
    "        json.dump({\"data\": train_list}, f, indent=4)\n",
    "    with open('val_data.json', 'w') as f:\n",
    "        json.dump({\"data\": val_list}, f, indent=4)\n",
    "    with open('test_data.json', 'w') as f:\n",
    "        json.dump({\"data\": test_list}, f, indent=4)\n",
    "    def count_files(data_list):\n",
    "        ptb_count = sum(1 for item in data_list if item['labels'] == \"1\")\n",
    "        non_ptb_count = sum(1 for item in data_list if item['labels'] == \"0\")\n",
    "        return ptb_count, non_ptb_count\n",
    "\n",
    "    train_ptb_audio, train_non_ptb_audio = count_files(train_list)\n",
    "    val_ptb_audio, val_non_ptb_audio = count_files(val_list)\n",
    "    test_ptb_audio, test_non_ptb_audio = count_files(test_list)\n",
    "    # 6. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î\n",
    "    print(\" AST DATASET PREPARATION SUMMARY (3-Way Patient-Level Split)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"üîπ TRAIN SET (Total Patients: {len(train_ids)})\")\n",
    "    print(f\"    PTB ID: {sorted(list(summary_ids['train_ptb']))}\")\n",
    "    print(f\"    Non-PTB ID: {sorted(list(summary_ids['train_non_ptb']))}\")\n",
    "    print(f\"    Total Audio Files: {len(train_list)} (PTB: {train_ptb_audio} files | Non-PTB: {train_non_ptb_audio} files)\")  \n",
    "    \n",
    "    print(f\"üî∏ VALIDATION SET (Total Patients: {len(val_ids)})\")\n",
    "    print(f\"    PTB ID: {sorted(list(summary_ids['val_ptb']))}\")\n",
    "    print(f\"    Non-PTB ID: {sorted(list(summary_ids['val_non_ptb']))}\")\n",
    "    print(f\"    Total Audio Files: {len(val_list)} (PTB: {val_ptb_audio} files | Non-PTB: {val_non_ptb_audio} files)\")   \n",
    "    \n",
    "    print(f\"üî¥ TEST SET (Total Patients: {len(test_ids)})\")\n",
    "    print(f\"    PTB ID: {sorted(list(summary_ids['test_ptb']))}\")\n",
    "    print(f\"    Non-PTB ID: {sorted(list(summary_ids['test_non_ptb']))}\")\n",
    "    print(f\"    Total Audio Files: {len(test_list)} (PTB: {test_ptb_audio} files | Non-PTB: {test_non_ptb_audio} files)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: ‡πÅ‡∏ö‡πà‡∏á Train 70%, Validate 10%, Test 20%\n",
    "prepare_ast_dataset(\"./Data\", train_ratio=0.6, val_ratio=0.2, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a6c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING AST-P SINGLE RUN (80/20 SPLIT) WITH VISUALIZATION\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m     13\u001b[0m     dataloader\u001b[38;5;241m.\u001b[39mAudiosetDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m, label_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_labels_indices.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, audio_conf\u001b[38;5;241m=\u001b[39mtrain_audio_conf),\n\u001b[0;32m     14\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m eval_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m     17\u001b[0m     dataloader\u001b[38;5;241m.\u001b[39mAudiosetDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m, label_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_labels_indices.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, audio_conf\u001b[38;5;241m=\u001b[39meval_audio_conf),\n\u001b[0;32m     18\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Spectrogram\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤ 1 Batch ‡∏à‡∏≤‡∏Å train_loader ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏†‡∏≤‡∏û\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ STARTING AST-P SINGLE RUN (80/20 SPLIT) WITH VISUALIZATION\")\n",
    "# 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "exp_dir = './exp/tb_ast_p_single_run'\n",
    "os.makedirs(f'{exp_dir}/models', exist_ok=True)\n",
    "MEAN_NORM = -3.2406702\n",
    "STD_NORM = 4.9710765\n",
    "# 2. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Data Config\n",
    "train_audio_conf = {'num_mel_bins': 128, 'target_length': 100, 'freqm': 24, 'timem': 20, 'mixup': 0.0, 'dataset': 'audioset', 'mode': 'train', 'mean': MEAN_NORM, 'std': STD_NORM, 'noise': False, 'skip_norm': False}\n",
    "eval_audio_conf = {'num_mel_bins': 128, 'target_length': 100, 'freqm': 0, 'timem': 0, 'mixup': 0.0, 'dataset': 'audioset', 'mode': 'evaluation', 'mean': MEAN_NORM, 'std': STD_NORM, 'noise': False, 'skip_norm': False}\n",
    "BATCH_SIZE = 8\n",
    "# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudiosetDataset('train_data.json', label_csv='class_labels_indices.csv', audio_conf=train_audio_conf),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudiosetDataset('eval_data.json', label_csv='class_labels_indices.csv', audio_conf=eval_audio_conf),\n",
    "    batch_size=BATCH_SIZE * 2, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Spectrogram\n",
    "# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤ 1 Batch ‡∏à‡∏≤‡∏Å train_loader ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏†‡∏≤‡∏û\n",
    "sample_inputs, sample_labels = next(iter(train_loader))\n",
    "# sample_inputs ‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î [batch_size, temporal_frame_num, frequency_bin_num]\n",
    "# ‡πÄ‡∏£‡∏≤‡∏î‡∏∂‡∏á index 0 ‡∏Ç‡∏≠‡∏á Batch ‡∏°‡∏≤‡∏û‡∏•‡πá‡∏≠‡∏ï\n",
    "spec_data = sample_inputs[0].numpy()  \n",
    "label_data = torch.argmax(sample_labels[0]).item()\n",
    "class_name = \"PTB\" if label_data == 1 else \"Non-PTB\"\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "# ‡∏û‡∏•‡πá‡∏≠‡∏ï‡πÇ‡∏î‡∏¢‡∏™‡∏•‡∏±‡∏ö‡πÅ‡∏Å‡∏ô (Transpose) ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà (128) ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏Å‡∏ô Y ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤ (100) ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏Å‡∏ô X\n",
    "plt.imshow(spec_data.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.title(f\"Example Log Mel Filterbank Spectrogram (Class: {class_name})\")\n",
    "plt.ylabel(\"Frequency Bins (128)\")\n",
    "plt.xlabel(\"Time Frames (100)\")\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚òùÔ∏è ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå Spectrogram 128 ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Normalization ‡πÅ‡∏•‡πâ‡∏ß ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ AST Model\")\n",
    "# ==========================================\n",
    "\n",
    "# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á AST-P Model \n",
    "ast_model = ASTModel(\n",
    "    label_dim=2, \n",
    "    fstride=10, \n",
    "    tstride=10, \n",
    "    input_fdim=128, \n",
    "    input_tdim=100, \n",
    "    imagenet_pretrain=True, \n",
    "    audioset_pretrain=True, \n",
    "    model_size='base384'\n",
    ")\n",
    "\n",
    "# 5. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Training Arguments\n",
    "args = argparse.Namespace(\n",
    "    exp_dir=exp_dir, dataset='audioset', n_class=2, lr=1e-5, n_epochs=30, batch_size=BATCH_SIZE, \n",
    "    n_print_steps=10, save_model=True, loss='CE', metrics='mAP', \n",
    "    lrscheduler_start=10, lrscheduler_step=5, lrscheduler_decay=0.5, \n",
    "    warmup=True, wa=True, wa_start=1, wa_end=30\n",
    ")\n",
    "\n",
    "# 6. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ Train\n",
    "print(\"\\nStarting Model Training...\")\n",
    "train(ast_model, train_loader, eval_loader, args)\n",
    "\n",
    "# 7. ‡πÇ‡∏´‡∏•‡∏î Best Model ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "best_model_path = f'{args.exp_dir}/models/best_audio_model.pth'\n",
    "best_model = ASTModel(label_dim=2, fstride=10, tstride=10, input_fdim=128, input_tdim=100, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=False)\n",
    "best_model = torch.nn.DataParallel(best_model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model = best_model.to(device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "\n",
    "stats, eval_loss = validate(best_model, eval_loader, args, epoch='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üìä [NEW] ‡∏ß‡∏≤‡∏î Confusion Matrix ‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î Eval\n",
    "# ==========================================\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "print(\"\\nüìà Generating Confusion Matrix...\")\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "best_model.eval() # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "with torch.no_grad():\n",
    "    for audio, labels in eval_loader:\n",
    "        audio = audio.to(device)\n",
    "        # AST Output ‡πÄ‡∏õ‡πá‡∏ô Raw Logits (‡πÑ‡∏°‡πà‡∏°‡∏µ Sigmoid/Softmax)\n",
    "        logits = best_model(audio) \n",
    "        # ‡πÉ‡∏ä‡πâ Argmax ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ Logit ‡∏™‡∏π‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_preds.extend(preds)\n",
    "        \n",
    "        # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ: ‡πÅ‡∏õ‡∏•‡∏á labels ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (0 ‡∏´‡∏£‡∏∑‡∏≠ 1) ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå\n",
    "        all_targets.extend(torch.argmax(labels, dim=1).numpy())\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü Confusion Matrix\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sys.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-PTB (0)', 'PTB (1)'], \n",
    "            yticklabels=['Non-PTB (0)', 'PTB (1)'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('AST-P Confusion Matrix (Eval Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e68244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, average_precision_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 1. ‡∏´‡∏≤ Best Epoch ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå result.csv ‡∏Ç‡∏≠‡∏á AST\n",
    "# ==========================================\n",
    "# ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á AST: [mAP, mAUC, precision, recall, d_prime, train_loss, valid_loss, cum_mAP, cum_mAUC, lr]\n",
    "csv_path = './exp/tb_ast_p_single_run/result.csv'\n",
    "df_results = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "# ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå index 1 ‡∏Ñ‡∏∑‡∏≠ mAUC ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Epoch\n",
    "best_epoch = df_results[1].idxmax() + 1\n",
    "best_mauc = df_results[1].max()\n",
    "print(f\"üåü Best Epoch: {best_epoch} (Validation AUC from log: {best_mauc:.4f})\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (Probabilities) ‡∏à‡∏≤‡∏Å Best Model\n",
    "# ==========================================\n",
    "print(\" Evaluating Best Model on Evaluation Set...\")\n",
    "all_probs = []\n",
    "all_targets = []\n",
    "\n",
    "best_model.eval() # ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "with torch.no_grad():\n",
    "    for audio, labels in eval_loader:\n",
    "        audio = audio.to(device)\n",
    "        logits = best_model(audio) \n",
    "        \n",
    "        # AST Output ‡πÄ‡∏õ‡πá‡∏ô Raw Logits (‡∏°‡∏µ 2 ‡∏Ñ‡πà‡∏≤ ‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô n_class=2)\n",
    "        # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ Softmax ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô (0-1) ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™ 1 (PTB)\n",
    "        probs = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "        \n",
    "        # ‡∏î‡∏∂‡∏á Label ‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏£‡∏¥‡∏á\n",
    "        targets = torch.argmax(labels, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_probs.extend(probs)\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "all_probs = np.array(all_probs)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# ==========================================\n",
    "# 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ AUROC, AUPRC ‡πÅ‡∏•‡∏∞‡∏´‡∏≤ Best Threshold\n",
    "# ==========================================\n",
    "fpr, tpr, roc_thresholds = roc_curve(all_targets, all_probs)\n",
    "auroc_val = auc(fpr, tpr)\n",
    "auprc_val = average_precision_score(all_targets, all_probs)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Sensitivity ‡πÅ‡∏•‡∏∞ Specificity ‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î Best Threshold\n",
    "# ==========================================\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î Threshold ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 0.5\n",
    "optimal_preds = (all_probs >= 0.5).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(all_targets, optimal_preds).ravel()\n",
    "\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\" Performance Metrics:\")\n",
    "print(f\" - AUROC:             {auroc_val:.4f}\")\n",
    "print(f\" - AUPRC:             {auprc_val:.4f}\")\n",
    "print(f\" - Sensitivity (TPR): {sensitivity:.4f}  (TP:{tp}, FN:{fn})\")\n",
    "print(f\" - Specificity (TNR): {specificity:.4f}  (TN:{tn}, FP:{fp})\")\n",
    "\n",
    "# 5. ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü ROC Curve ‡πÅ‡∏•‡∏∞ Confusion Matrix ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ô\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ---- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 1: ROC Curve ----\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2.5, label=f'AUROC = {auroc_val:.4f}')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# ‡∏°‡∏≤‡∏£‡πå‡∏Ñ‡∏à‡∏∏‡∏î Threshold ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate (Sensitivity)', fontsize=12)\n",
    "axes[0].set_title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
    "axes[0].legend(loc=\"lower right\", fontsize=11)\n",
    "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# ---- ‡∏Å‡∏£‡∏≤‡∏ü‡∏ó‡∏µ‡πà 2: Confusion Matrix ----\n",
    "cm_optimal = confusion_matrix(all_targets, optimal_preds)\n",
    "sns.heatmap(cm_optimal, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Non-PTB (0)', 'PTB (1)'], \n",
    "            yticklabels=['Non-PTB (0)', 'PTB (1)'],\n",
    "            annot_kws={\"size\": 14}, ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_title(f'Confusion Matrix (@ Threshold {0.5:.4f})', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
